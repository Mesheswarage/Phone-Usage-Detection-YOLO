# Phone-Usage-Detection-YOLO
This project detects Phone Usage By utilizing keypoints-based pose estimation, the project identifies patterns that suggest phone engagement. The system employs 'yolov8n-pose' pose estimation model to pinpoint keypoints on the human body, which enables the calculation of angles, distances, and positions for accurate phone usage detection. 

Key Features:

Detects phone usage through an analysis of head and hand orientations.

Incorporates hand angles, hand distance, and wrist position for enhanced accuracy.

Utilizes pose estimation libraries to identify keypoints on the human body.

Calculates angles, distances, and positions to infer phone usage gestures.

Provides a user-friendly visualization of detected phone usage on input frames.

Offers configurable parameters for adaptable performance across different contexts.

https://youtu.be/H7x5nJHqNas
